{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n",
      "(60000,)\n",
      "(784, 60000)\n",
      "(10000,)\n",
      "(784, 10000)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt(\"mnist_train.csv\", delimiter=',')\n",
    "test_data = np.genfromtxt(\"mnist_test.csv\", delimiter=',')\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "N_train = 60000\n",
    "N_test = 10000\n",
    "train_labels = train_data[:N_train, 0].astype(int)\n",
    "train_images = train_data[:N_train, 1:].T/255\n",
    "test_labels = test_data[:N_test, 0].astype(int)\n",
    "test_images = test_data[:N_test, 1:].T/255\n",
    "print(train_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    max_elem = np.max(x, axis = 0)\n",
    "    y = x - max_elem\n",
    "    y = np.exp(y)\n",
    "    sums = np.sum(y, axis = 0)\n",
    "    return y / sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_label):\n",
    "    C = int(y_label.max() + 1)\n",
    "    enc = np.zeros((C, y_label.size))\n",
    "    enc[y_label.astype(int), np.arange(y_label.size)] = 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, sizes):\n",
    "        self.w0 = np.random.randn(sizes[1],sizes[0])\n",
    "        self.w1 = np.random.randn(sizes[2],sizes[1])\n",
    "        self.mw0 = np.zeros_like(self.w0)\n",
    "        self.mw1 = np.zeros_like(self.w1)\n",
    "    \n",
    "    \n",
    "    #forward pass \n",
    "    def train(self, X, y_label, epochs = 20, alpha = 0.1, beta = 0.8): \n",
    "        y_one_hot = one_hot_encoding(y_label)\n",
    "        for epoch in range(epochs):\n",
    "            a0 = self.w0 @ X\n",
    "            z0 = np.maximum(a0, 0)\n",
    "            a1 = self.w1 @ z0\n",
    "            y = softmax(a1)\n",
    "            \n",
    "            loss = -(np.log(y + eps) * y_one_hot).sum() / y_label.size\n",
    "            accuracy = (np.argmax(y, axis = 0) == y_label). sum() / y_label.size\n",
    "            \n",
    "            #backward pass\n",
    "            delta_a_1 = y - y_one_hot\n",
    "            grad_w1 = delta_a_1 @ z0.T\n",
    "            delta_z_0 = self.w1.T @ delta_a_1\n",
    "            delta_a_0 = delta_z_0.copy()\n",
    "            delta_a_0[a0<0] = 0\n",
    "            grad_w0 = delta_a_0 @ X.T\n",
    "            \n",
    "            self.mw0 = beta * self.mw0 - alpha * grad_w0\n",
    "            self.mw1 = beta * self.mw1 - alpha * grad_w1\n",
    "            \n",
    "            self.w0 += self.mw0\n",
    "            self.w1 += self.mw1\n",
    "            \n",
    "            print(\"  Epoch:    \", epoch, \"\\n\",\n",
    "                \" Loss:     \", loss, \"\\n\",\n",
    "                 \" Accuracy: \", accuracy * 100, \"%\", \"\\n\")\n",
    "                 \n",
    "                 \n",
    "            \n",
    "            \n",
    "    def stochastic_train(self, X, y_label, epochs = 20, alpha = 0.1, beta = 0.8, mb_size = 100): \n",
    "        y_one_hot = one_hot_encoding(y_label)\n",
    "        iters_per_epoch = int(y_label.size/mb_size)\n",
    "        indices = np.arange(y_label.size)\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            X_sh = X[:, indices]\n",
    "            y_one_sh = y_one_hot[:,  indices]\n",
    "\n",
    "            for it in range(iters_per_epoch):\n",
    "                X_iter = X_sh[:, it * mb_size:(it +  1) * mb_size]\n",
    "                y_one_iter = y_one_sh[:, it * mb_size:(it + 1) * mb_size]\n",
    "\n",
    "                a0 = self.w0 @ X_iter\n",
    "                z0 = np.maximum(a0, 0)\n",
    "                a1 = self.w1 @ z0\n",
    "                y = softmax(a1)\n",
    "\n",
    "                #backward pass\n",
    "                delta_a_1 = y - y_one_iter\n",
    "                grad_w1 = delta_a_1 @ z0.T\n",
    "                delta_z_0 = self.w1.T @ delta_a_1\n",
    "                delta_a_0 = delta_z_0.copy()\n",
    "                delta_a_0[a0<0] = 0\n",
    "                grad_w0 = delta_a_0 @ X_iter.T\n",
    "\n",
    "                self.mw0 = beta * self.mw0 - alpha * grad_w0\n",
    "                self.mw1 = beta * self.mw1 - alpha * grad_w1\n",
    "\n",
    "                self.w0 += self.mw0\n",
    "                self.w1 += self.mw1\n",
    "\n",
    "            loss, accuracy = self.evaluate(X, y_label)\n",
    "            print(\"  Epoch:    \", epoch, \"\\n\",\n",
    "                                \" Loss:     \", loss, \"\\n\",\n",
    "                                 \" Accuracy: \", accuracy * 100, \"%\", \"\\n\")\n",
    "\n",
    "            \n",
    "    def evaluate (self, X, y_label):\n",
    "        y_one_hot = one_hot_encoding(y_label)\n",
    "        a0 = self.w0 @ X\n",
    "        z0 = np.maximum(a0, 0)\n",
    "        a1 = self.w1 @ z0\n",
    "        y = softmax(a1)\n",
    "        loss = -(np.log(y + eps) * y_one_hot).sum() / y_label.size\n",
    "        accuracy = (np.argmax(y, axis = 0) == y_label). sum() / y_label.size\n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch:     0 \n",
      "  Loss:      0.45983653049842454 \n",
      "  Accuracy:  86.89166666666667 % \n",
      "\n",
      "  Epoch:     1 \n",
      "  Loss:      0.3369895648449478 \n",
      "  Accuracy:  90.62666666666667 % \n",
      "\n",
      "  Epoch:     2 \n",
      "  Loss:      0.30453198974090573 \n",
      "  Accuracy:  91.29666666666667 % \n",
      "\n",
      "  Epoch:     3 \n",
      "  Loss:      0.2397895915132129 \n",
      "  Accuracy:  93.02166666666668 % \n",
      "\n",
      "  Epoch:     4 \n",
      "  Loss:      0.23616101024098005 \n",
      "  Accuracy:  93.195 % \n",
      "\n",
      "  Epoch:     5 \n",
      "  Loss:      0.19454968410455994 \n",
      "  Accuracy:  94.28999999999999 % \n",
      "\n",
      "  Epoch:     6 \n",
      "  Loss:      0.18222829501472262 \n",
      "  Accuracy:  94.63833333333334 % \n",
      "\n",
      "  Epoch:     7 \n",
      "  Loss:      0.19592897469491394 \n",
      "  Accuracy:  94.325 % \n",
      "\n",
      "  Epoch:     8 \n",
      "  Loss:      0.17042735390359018 \n",
      "  Accuracy:  95.01666666666667 % \n",
      "\n",
      "  Epoch:     9 \n",
      "  Loss:      0.19736157754263056 \n",
      "  Accuracy:  94.60833333333333 % \n",
      "\n",
      "  Epoch:     10 \n",
      "  Loss:      0.14990240859315557 \n",
      "  Accuracy:  95.49333333333333 % \n",
      "\n",
      "  Epoch:     11 \n",
      "  Loss:      0.1483166875462938 \n",
      "  Accuracy:  95.585 % \n",
      "\n",
      "  Epoch:     12 \n",
      "  Loss:      0.14335608527378188 \n",
      "  Accuracy:  95.72 % \n",
      "\n",
      "  Epoch:     13 \n",
      "  Loss:      0.13341171588816167 \n",
      "  Accuracy:  96.11166666666666 % \n",
      "\n",
      "  Epoch:     14 \n",
      "  Loss:      0.12229854235603511 \n",
      "  Accuracy:  96.29333333333334 % \n",
      "\n",
      "  Epoch:     15 \n",
      "  Loss:      0.11266498128119214 \n",
      "  Accuracy:  96.58833333333334 % \n",
      "\n",
      "  Epoch:     16 \n",
      "  Loss:      0.11543728319893892 \n",
      "  Accuracy:  96.54333333333334 % \n",
      "\n",
      "  Epoch:     17 \n",
      "  Loss:      0.11157316818483176 \n",
      "  Accuracy:  96.65833333333333 % \n",
      "\n",
      "  Epoch:     18 \n",
      "  Loss:      0.10723478202854067 \n",
      "  Accuracy:  96.7 % \n",
      "\n",
      "  Epoch:     19 \n",
      "  Loss:      0.09962355245222698 \n",
      "  Accuracy:  97.00333333333333 % \n",
      "\n",
      "  Epoch:     20 \n",
      "  Loss:      0.09659491689495123 \n",
      "  Accuracy:  97.11166666666666 % \n",
      "\n",
      "  Epoch:     21 \n",
      "  Loss:      0.1039116930453127 \n",
      "  Accuracy:  96.86166666666666 % \n",
      "\n",
      "  Epoch:     22 \n",
      "  Loss:      0.09049707292992207 \n",
      "  Accuracy:  97.24166666666667 % \n",
      "\n",
      "  Epoch:     23 \n",
      "  Loss:      0.091223528946507 \n",
      "  Accuracy:  97.21333333333332 % \n",
      "\n",
      "  Epoch:     24 \n",
      "  Loss:      0.08309238657506475 \n",
      "  Accuracy:  97.49666666666667 % \n",
      "\n",
      "  Epoch:     25 \n",
      "  Loss:      0.07967105089664116 \n",
      "  Accuracy:  97.56166666666667 % \n",
      "\n",
      "  Epoch:     26 \n",
      "  Loss:      0.08224101929122521 \n",
      "  Accuracy:  97.44500000000001 % \n",
      "\n",
      "  Epoch:     27 \n",
      "  Loss:      0.07559263123627784 \n",
      "  Accuracy:  97.63333333333334 % \n",
      "\n",
      "  Epoch:     28 \n",
      "  Loss:      0.07491848185922112 \n",
      "  Accuracy:  97.67333333333333 % \n",
      "\n",
      "  Epoch:     29 \n",
      "  Loss:      0.06993296685041055 \n",
      "  Accuracy:  97.78 % \n",
      "\n",
      "  Epoch:     30 \n",
      "  Loss:      0.07190899913560092 \n",
      "  Accuracy:  97.79166666666667 % \n",
      "\n",
      "  Epoch:     31 \n",
      "  Loss:      0.06492616352320675 \n",
      "  Accuracy:  98.02 % \n",
      "\n",
      "  Epoch:     32 \n",
      "  Loss:      0.06275027972745073 \n",
      "  Accuracy:  98.11166666666666 % \n",
      "\n",
      "  Epoch:     33 \n",
      "  Loss:      0.061835818275132286 \n",
      "  Accuracy:  98.09333333333333 % \n",
      "\n",
      "  Epoch:     34 \n",
      "  Loss:      0.05974192093008728 \n",
      "  Accuracy:  98.15166666666667 % \n",
      "\n",
      "  Epoch:     35 \n",
      "  Loss:      0.0632601436962482 \n",
      "  Accuracy:  97.995 % \n",
      "\n",
      "  Epoch:     36 \n",
      "  Loss:      0.06253645502332429 \n",
      "  Accuracy:  98.085 % \n",
      "\n",
      "  Epoch:     37 \n",
      "  Loss:      0.05725930849621497 \n",
      "  Accuracy:  98.26666666666667 % \n",
      "\n",
      "  Epoch:     38 \n",
      "  Loss:      0.05291078552062675 \n",
      "  Accuracy:  98.35833333333333 % \n",
      "\n",
      "  Epoch:     39 \n",
      "  Loss:      0.06508783201697078 \n",
      "  Accuracy:  97.95666666666666 % \n",
      "\n",
      "  Epoch:     40 \n",
      "  Loss:      0.05949314410498447 \n",
      "  Accuracy:  98.13166666666666 % \n",
      "\n",
      "  Epoch:     41 \n",
      "  Loss:      0.05303351585176193 \n",
      "  Accuracy:  98.38333333333334 % \n",
      "\n",
      "  Epoch:     42 \n",
      "  Loss:      0.04962509358006105 \n",
      "  Accuracy:  98.46666666666667 % \n",
      "\n",
      "  Epoch:     43 \n",
      "  Loss:      0.055180439955990306 \n",
      "  Accuracy:  98.24666666666667 % \n",
      "\n",
      "  Epoch:     44 \n",
      "  Loss:      0.050421111038140766 \n",
      "  Accuracy:  98.375 % \n",
      "\n",
      "  Epoch:     45 \n",
      "  Loss:      0.045870359414232655 \n",
      "  Accuracy:  98.57000000000001 % \n",
      "\n",
      "  Epoch:     46 \n",
      "  Loss:      0.046495009492073455 \n",
      "  Accuracy:  98.52499999999999 % \n",
      "\n",
      "  Epoch:     47 \n",
      "  Loss:      0.04514192600772298 \n",
      "  Accuracy:  98.61166666666666 % \n",
      "\n",
      "  Epoch:     48 \n",
      "  Loss:      0.04165324100691423 \n",
      "  Accuracy:  98.75333333333333 % \n",
      "\n",
      "  Epoch:     49 \n",
      "  Loss:      0.04025834977686 \n",
      "  Accuracy:  98.75 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_net = NN([784,100,10])\n",
    "mnist_net.stochastic_train(train_images, train_labels, mb_size  = 100, epochs = 50, \n",
    "                           alpha = 1e-3, beta = 0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss:      0.2696922159243394 \n",
      " Accuracy:  95.45 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = mnist_net.evaluate(test_images, test_labels)\n",
    "print(\" Loss:     \", loss, \"\\n\",\n",
    "      \"Accuracy: \", accuracy * 100, \"%\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_net.w0[65].reshape(28,28))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
