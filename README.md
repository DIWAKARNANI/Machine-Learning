<img src="https://raw.githubusercontent.com/ElizaLo/Machine-Learning/master/images/Banner_Machine_Learning.png" width="900" height="100">

This repository contains examples of popular machine learning algorithms implemented in Python with mathematics behind them being explained. 

This repository continues to be constantly updated.


> - [ ] For **Octave/MatLab** version of Machine Learning algorithms please check [Machine Learning Course in Octave / MatLab](https://github.com/ElizaLo/Machine-Learning-Course-Octave) repository.

> - [ ] For **Deep Learning** algorithms please check [Deep Learning](https://github.com/ElizaLo/Deep-Learning) repository.

> - [ ] For **Natural Language Processing** (NLU = NLP + NLG) please check [Natural Language Processing](https://github.com/ElizaLo/NLP-Natural-Language-Processing) repository.

> - [ ] For **Computer Vision** please check [Computer Vision](https://github.com/ElizaLo/Computer-Vision) repository.


## Table of Contents

- [Machine Learning Map](https://github.com/ElizaLo/Machine-Learning#machine-learning-map)
- [Courses](https://github.com/ElizaLo/Machine-Learning#-courses)
- [Online Courses](https://github.com/ElizaLo/Machine-Learning#-online-courses)
- [YouTube Videos](https://github.com/ElizaLo/Machine-Learning#-youtube-videos)
- [Books](https://github.com/ElizaLo/Machine-Learning#-books)
- [Websites](https://github.com/ElizaLo/Machine-Learning#%EF%B8%8F-websites)
- [GitHub Repositories](https://github.com/ElizaLo/Machine-Learning#octocat-github-repositories) :octocat:
- [Awesome List](https://github.com/ElizaLo/Machine-Learning#awesome-list) :octocat:
- [Other](https://github.com/ElizaLo/Machine-Learning#-other)
- [Neural Networks](https://github.com/ElizaLo/Machine-Learning#neural-networks)
- [Reinforcement Learning ](https://github.com/ElizaLo/Machine-Learning#reinforcement-learning)
  - Books
  - Classes
  - Task / Tutorials
  - GitHub Repositories
- [Linear algebra](https://github.com/ElizaLo/Machine-Learning#linear-algebra)
- [Theory of Probability and Mathematical Statistics](https://github.com/ElizaLo/Machine-Learning#theory-of-probability-and-mathematical-statistics)
- [Algorithms](https://github.com/ElizaLo/Machine-Learning#algorithms)
- [Python, IPython, Scikit-learn etc.](https://github.com/ElizaLo/Machine-Learning#python-ipython-scikit-learn-etc)
- [Code editors](https://github.com/ElizaLo/Machine-Learning#code-editors)
- [JavaScript-libraries for visualizing](https://github.com/ElizaLo/Machine-Learning#javascript-libraries-for-visualizing)
- [R](https://github.com/ElizaLo/Machine-Learning#r)
- [LaTeX](https://github.com/ElizaLo/Machine-Learning#latex)
- [Open Datasets](https://github.com/ElizaLo/Machine-Learning#-open-datasets-list)
- [Reddit](https://github.com/ElizaLo/Machine-Learning#reddit)
- [Social Networks (chanels, chats, groups, etc.)](https://github.com/ElizaLo/Machine-Learning#social-networks-chanels-chats-groups-etc)
- Implementation
  - [Supervised Learning](https://github.com/ElizaLo/Machine-Learning/tree/master/Supervised%20Learning)
    - Classification
      - [K Nearest Neighbor, K-NN](https://github.com/ElizaLo/ML-with-Jupiter#k-nearest-neighbor)
      - [Logistic Regression](https://github.com/ElizaLo/ML-with-Jupiter#logistic-regression)
    - Regression
      - [Linear Regression](https://github.com/ElizaLo/ML-with-Jupiter#linear-regression)
      - [Polynomial Regression](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#polynomial-regression)
  - [Unsupervised Learning](https://github.com/ElizaLo/Machine-Learning/tree/master/Unsupervised%20Learning)
    - Clustering
      - [K-Means](https://github.com/ElizaLo/Machine-Learning/tree/master/Unsupervised%20Learning/Clustering/K-Means)
  - [Neural Networks](https://github.com/ElizaLo/Machine-Learning/tree/master/Neural%20Networks)
      - [CNN](https://github.com/ElizaLo/Machine-Learning/blob/master/Neural%20Networks/CNN.ipynb)
      - [FCNN](https://github.com/ElizaLo/Machine-Learning/blob/master/Neural%20Networks/FCNN.ipynb)
      - [GRU](https://github.com/ElizaLo/Machine-Learning/blob/master/Neural%20Networks/GRU.ipynb)
- [What's is the difference between train, validation and test set, in neural networks?](https://github.com/ElizaLo/Machine-Learning#whats-is-the-difference-between-train-validation-and-test-set-in-neural-networks)
- Projects
  - [Spam Detection](https://github.com/ElizaLo/ML-with-Jupiter#spam-detection)
  - [Text Generator](https://github.com/ElizaLo/ML-with-Jupiter#text-generator)
  - Quora Insincere Questions Classification
  - [Question Answering System using BiDAF Model on SQuAD](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD)

    
## Machine Learning Map
![machine-learning-map.png](https://raw.githubusercontent.com/ElizaLo/Machine-Learning/master/images/machine-learning-map.png)


## üéì Courses 

- [ ] [–ö—É—Ä—Å –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –í–æ—Ä–æ–Ω—Ü–æ–≤](https://www.youtube.com/playlist?list=PLww5O9qI8iPP-mZf8mCMff3eMWFBHr0m1)
- [ ] [–ö—É—Ä—Å "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ" –Ω–∞ –§–ö–ù –í–®–≠, –ï–≤–≥–µ–Ω–∏–π –°–æ–∫–æ–ª–æ–≤](https://github.com/esokolov/ml-course-hse)
- [ ] [Data Mining](https://www.cs.utah.edu/~jeffp/teaching/cs5955.html)
- [x] [Deep Learning LUN Cources](https://github.com/ElizaLo/Machine-Learning/tree/master/Deep%20Learning%20LUN%20Cources)
- [ ] [–¢–æ–Ω–Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∫—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é, –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º, –≤ —Ç–æ–º —á–∏—Å–ª–µ 14 –∫—É—Ä—Å–æ–≤ –ø–æ ML](https://github.com/prakhar1989/awesome-courses)

üîπ **Introductory Lectures:**

These are great courses to get started in machine learning and AI. No prior experience in ML and AI is needed. You should have some knowledge of linear algebra, introductory calculus and probability. Some programming experience is also recommended.

- [ ] [Machine Learning (Stanford CS229)](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) 
  - [Course website](http://cs229.stanford.edu/syllabus-autumn2018.html)
  - This modern classic of machine learning courses is a great starting point to understand the concepts and techniques of machine learning. The course covers many widely used techniques, The lecture notes are detailed and review necessary mathematical concepts.
- [ ] [Convolutional Neural Networks for Visual Recognition (Stanford CS231n)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
  - [Course website](https://cs231n.github.io)
  - ([:octocat: repo on github](https://github.com/cs231n)) ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π –¥–µ—Å—è—Ç–∏–Ω–µ–¥–µ–ª—å–Ω—ã–π –∫—É—Ä—Å –ø–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º—É –∑—Ä–µ–Ω–∏—é.
  - A great way to start with deep learning. The course focuses on convolutional neural networks and computer vision, but also gives an overview on recurrent networks and reinforcement learning.
- [ ] [Introduction to Artificial Intelligence (UC Berkeley CS188)](https://www.youtube.com/playlist?list=PL7k0r4t5c108AZRwfW-FhnkZ0sCKBChLH)
  - [Course website](https://inst.eecs.berkeley.edu/~cs188/fa18/index.html)
  - Covers the whole field of AI. From search methods, game trees and machine learning to Bayesian networks and reinforcement learning.
- [ ] [Applied Machine Learning 2020 (Columbia)](https://www.youtube.com/playlist?list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM)
  - Alternative to Stanford CS229. As the name implies, this course takes a more applied perspective than Andrew Ng's machine learning lecture at Stanford. You will see more code than mathematics. Concepts and algorithms are using the popular Python libraries scikit-learn and Keras.
- [ ] [Introduction to Reinforcement learning with David Silver (DeepMind)](https://www.youtube.com/playlist?list=PLqYmG7hTraZBiG_XpjnPrSNw-1XQaM_gB)
  - [UCL Course on Reinforcement Learning by David Silver ](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
  - [Course website](https://www.davidsilver.uk/teaching/)
  - Introduction to reinforcement learning by one of the leading researchers behind AlphaGo and AlphaZero.
- [ ] [Natural Language Processing with Deep Learning (Stanford CS224N)](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) 
  - [Course website](http://web.stanford.edu/class/cs224n/)
  - Modern NLP techniques from recurrent neural networks and word embeddings to transformers and self-attention. Covers applied topics like questions answering and text generation.

üî∏ **Advanced Lectures:**

Advanced courses that require prior knowledge in machine learning and AI.

- [ ] [Deep Unsupervised Learning (UC Berkeley CS294)](https://www.youtube.com/channel/UCf4SX8kAZM_oGcZjMREsU9w/videos) 
  - [Course website](https://sites.google.com/view/berkeley-cs294-158-sp19/home)
- [ ] [Frontiers of Deep Learning (Simons Institute)](https://www.youtube.com/playlist?list=PLgKuh-lKre11ekU7g-Z_qsvjDD8cT-hi9)
  - [Course website](https://simons.berkeley.edu/workshops/dl2019-1)
- [ ] [New Deep Learning Techniques](https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdM0zXj31HWjG9t9Q0v2xYN)
  - [Course website](http://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=overview)
- [ ] [Geometry of Deep Learning (Microsoft Research)](https://www.youtube.com/playlist?list=PLD7HFcN7LXRe30qq36It2XCljxc340O_d)
  - [Course website](https://www.microsoft.com/en-us/research/event/ai-institute-2019/)
- [ ] [Deep Multi-Task and Meta Learning (Stanford CS330)](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)
  - [Course Website](http://cs330.stanford.edu/)
- [ ] [Mathematics of Machine Learning Summer School 2019 (University of Washington)](https://www.youtube.com/playlist?list=PLTPQEx-31JXhguCush5J7OGnEORofoCW9)
  - [Course Website](http://mathofml.cs.washington.edu/)
- [ ] [Probabilistic Graphical Models (Carneggie Mellon University)](https://www.youtube.com/playlist?list=PLoZgVqqHOumTY2CAQHL45tQp6kmDnDcqn)
  - [Course Website](https://sailinglab.github.io/pgm-spring-2019/)
- [ ] [Probabilistic and Statistical Machine Learning 2020 (University of T√ºbingen)](https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd)
- [ ] [Statistical Machine Learning 2020 (University of T√ºbingen)](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC)
- [ ] [Mobile Sensing and Robotics 2019 (Bonn University)](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQJXx-x0t23RmRbjp_yMb4v)
- [ ] [Sensors and State Estimation Course 2020 (Bonn University)](https://www.youtube.com/playlist?list=PLgnQpQtFTOGQh_J16IMwDlji18SWQ2PZ6)
- [ ] [Photogrammetry 2015 (Bonn University)](https://www.youtube.com/playlist?list=PLgnQpQtFTOGRsi5vzy9PiQpNWHjq-bKN1)
- [ ] [Advanced Deep Learning & Reinforcement Learning 2020 (DeepMind / UCL)](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)
- [ ] [Data-Driven Dynamical Systems with Machine Learning](https://www.youtube.com/playlist?list=PLMrJAkhIeNNR6DzT17-MM1GHLkuYVjhyt)
- [ ] [Data-Driven Control with Machine Learning](https://www.youtube.com/playlist?list=PLMrJAkhIeNNQkv98vuPjO2X2qJO_UPeWR)
- [ ] [ECE AI Seminar Series 2020 (NYU)](https://www.youtube.com/playlist?list=PLhwo5ntex8iY9xhpSwWas451NgVuqBE7U)
- [ ] [CS287 Advanced Robotics at UC Berkeley Fall 2019](https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNBPJdt8WamRAt4XKc639wF)
- [ ] [CSEP 546 - Machine Learning (AU 2019) (U of Washington)](https://www.youtube.com/playlist?list=PLTPQEx-31JXj87XLsYutYGKw6K9dNaD36)
- [ ] [Deep Reinforcment Learning, Decision Making and Control (UC Berkeley CS285)](https://www.youtube.com/playlist?list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A)
- [ ] [Stanford Convex Optimization](https://www.youtube.com/playlist?list=PLdrixi40lpQm5ksInXlRon1eRwq_gzIcw)
- [ ] [Stanford CS224U: Natural Language Understanding, Spring 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)
- [ ] [Full Stack Deep Learning 2019](https://www.youtube.com/playlist?list=PL1T8fO7ArWlcf3Hc4VMEVBlH8HZm_NbeB)
- [ ] [Emerging Challenges in Deep Learning](https://www.youtube.com/playlist?list=PLgKuh-lKre10BpafDrv0fg2VNUweWXWVd)
- [ ] [Deep Bayes 2019 Summer School](https://www.youtube.com/playlist?list=PLe5rNUydzV9QHe8VDStpU0o8Yp63OecdW)
- [ ] [CMU Neural Nets for NLP 2020](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ)
- [ ] [New Directions in Reinforcement Learning and Control (Institure for Advanced Study)](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ61sGqd6cbWCmTc275NrKu3)
- [ ] [Workshop on Theory of Deep Learning: Where next (Institure for Advanced Study)](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ5dqqg_S-rgJqSFeH4DQqFQ)
- [ ] [Deep Learning: Alchemy or Science? (Institure for Advanced Study)](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ7aAxhIHALBoh8l6-UxmMNP)
- [ ] [Theoretical Machine Learning Lecture Series (Institure for Advanced Study)](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ5VLprf2VUfC0h1zOGvV_gz)

## üîπ Online Courses

- [ ] [–ü–µ—Ä–µ—á–µ–Ω—å –ª—É—á—à–∏—Ö –∫—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ª—é–±—ã–º –æ–±–ª–∞—Å—Ç—è–º –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏](https://www.quora.com/What-are-the-best-online-college-level-mathematics-courses)
- [ ] Coursera:
  * [Spesialization: Advanced Machine Learning ](https://www.coursera.org/specializations/aml)
  * [Machine Learning](https://www.coursera.org/learn/machine-learning) –æ—Ç Andrew Ng (Stanford University) ‚Äì —Å–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∫—É—Ä—Å –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ, –≤–º–µ—Å—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ü–∏—Ç–æ–Ω–∞ –∏–ª–∏ R ‚Äì Matlab/Octave)
  * –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è [–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ](https://www.coursera.org/specializations/mashinnoye-obucheniye) –æ—Ç –ú–§–¢–ò –∏ –Ø–Ω–¥–µ–∫—Å–∞. –ü–æ —ç—Ç–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –µ—Å—Ç—å –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π [:octocat: —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/demidovakatya/mashinnoye-obucheniye)
  * [Machine Learning Foundations: A Case Study Approach](https://www.coursera.org/learn/ml-foundations/home/info) ‚Äî –æ—á–µ–Ω—å –¥–æ—Ö–æ–¥—á–∏–≤—ã–π –∫—É—Ä—Å, –ø–æ–¥—Ö–æ–¥–∏—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–∞–º–æ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∫—É—Ä—Å–∞ –ø–æ ML
  * [Practical Predictive Analytics: Models and Methods](https://www.coursera.org/learn/predictive-analytics/)
  * [Calculus: Single Variable Part 1](https://www.coursera.org/learn/single-variable-calculus) –æ—Ç University of Pennsylvania;
  * [Calculus One](https://www.coursera.org/learn/calculus1) –æ—Ç The Ohio State University
  * [–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞](https://www.coursera.org/learn/modern-combinatorics) –æ—Ç –ú–§–¢–ò, –≤–µ–¥—ë—Ç –†–∞–π–≥–æ—Ä–æ–¥—Å–∫–∏–π –ê.–ú.
  * [–¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö](https://www.coursera.org/learn/probability-theory-basics/home/info), –∞ —Ç–∞–∫–∂–µ [–Ω–∞ OpenEdu](https://openedu.ru/course/mipt/PROBTH/) ‚Äî –∫—É—Ä—Å –æ—Ç –ú–§–¢–ò, –≤–µ–¥—ë—Ç –†–∞–π–≥–æ—Ä–æ–¥—Å–∫–∏–π –ê.–ú.
  * [–õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞](https://www.coursera.org/course/linalg) –æ—Ç –í–®–≠. –ö—É—Ä—Å –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä—ã –¥–ª—è –Ω–µ–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–æ–≤, –ø–æ–¥—Ö–æ–¥–∏—Ç ¬´–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞¬ª
  * [–≠–∫–æ–Ω–æ–º–µ—Ç—Ä–∏–∫–∞](https://www.coursera.org/learn/ekonometrika/) (Econometrics) ‚Äî 10-–Ω–µ–¥–µ–ª—å–Ω—ã–π –∫—É—Ä—Å –æ—Ç –í–®–≠
  * [Customer Analytics](https://www.coursera.org/learn/wharton-customer-analytics) ‚Äì –∫—É—Ä—Å –æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö. –î–ª—è –ª—é–¥–µ–π, —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–≤—à–∏—Ö—Å—è –≤ DS –∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—â–∏—Ö, –Ω–∞ –∫–æ–π —ç—Ç–æ –≤—Å—ë
  * [Social Network Analysis](https://www.coursera.org/course/sna) –æ—Ç University of Michigan
  * [Social and Economic Networks: Models and Analysis](https://www.coursera.org/course/networksonline) –æ—Ç Stanford University
  * [Introduction to Recommender Systems](https://www.coursera.org/learn/recommender-systems) ‚Äì –≤–æ—Å—å–º–∏–Ω–µ–¥–µ–ª—å–Ω—ã–π –∫—É—Ä—Å –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –æ—Ç —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ú–∏–Ω–Ω–µ—Å–æ—Ç—ã
  * –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è [Machine Learning](https://www.coursera.org/specializations/machine-learning) –æ—Ç Washington University.
- [ ]  Udacity:
  * [Machine Learning Engineer Nanodegree](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009)
  * [Data Analyst Nanodegree](https://www.udacity.com/course/data-analyst-nanodegree--nd002)
  * [Intro to Machine Learning](https://www.udacity.com/courses/ud120) ‚Äî this will teach you the end-to-end process of investigating data through a machine learning lens
  * [Intro to Descriptive Statistics](https://www.udacity.com/courses/ud827) ‚Äì –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫—É—Ä—Å –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤
- [ ] Edx:
  * [Data Science and Engineering with Spark](https://www.edx.org/xseries/data-science-engineering-spark#courses)
  * [Introduction to Computational Thinking and Data Science](https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-3)
  * [MITx: 6.041x Introduction to Probability - The Science of Uncertainty](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-1)
  * [The Analytics Edge](https://www.edx.org/course/analytics-edge-mitx-15-071x-2)
- [ ] [Learning from Data](https://work.caltech.edu/telecourse.html) ‚Äì –≤–≤–µ–¥–µ–Ω–∏–µ –≤ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–æ—Ä–∏—è, –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)
- [ ] [–í–∏–¥–µ–æ–∑–∞–ø–∏—Å–∏ –ª–µ–∫—Ü–∏–π –®–∫–æ–ª—ã –ê–Ω–∞–ª–∏–∑–∞ –î–∞–Ω–Ω—ã—Ö](https://yandexdataschool.ru/edu-process/courses)
- [ ] [Intro to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science) ‚Äì –æ—Å–Ω–æ–≤—ã Python –∏ –Ω–µ–º–Ω–æ–≥–æ –ø—Ä–æ NumPy
- [ ] –ö—É—Ä—Å –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –Ω–∞ [stepic.org](http://stepic.org) ‚Äî –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, —Ü–µ–ª–∏–∫–æ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- [ ] [Data Science and Machine Learning Essentials](https://mva.microsoft.com/en-US/training-courses/data-science-and-machine-learning-essentials-14100) –æ—Ç Microsoft 


## üü• YouTube Videos

- [ ] [TensorFlow: Coding TensorFlow](https://www.youtube.com/playlist?list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx) playlist
- [ ] [Google Cloud Platform: AI Adventures](https://www.youtube.com/playlist?list=PLIivdWyY5sqJxnwJhe3etaK7utrBiPBQ2)
- [ ] [3Blue1Brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists) channel

## üìö Books

- [ ] [100+ Free Data Science Books](http://www.learndatasci.com/free-books/) ‚Äì –±–æ–ª–µ–µ 100 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∫–Ω–∏–≥ –ø–æ Data Science
- [ ] [16 Free Machine Learning Books](https://hackerlists.com/free-machine-learning-books/) ‚Äî –µ—â—ë 16 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∫–Ω–∏–≥ –ø–æ ML
- [ ] [An Introduction to Statistical Learning](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/Tensor%20Calculus)
- [ ] [Tensor Calculus](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)
- [ ] [The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)](https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576/ref=asc_df_0387848576/?tag=hyprod-20&linkCode=df0&hvadid=312140868236&hvpos=1o2&hvnetw=g&hvrand=14103077512698652064&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9031958&hvtargid=aud-801738734305:pla-487139763557&psc=1)
 - [ ] [Pattern Recognition and Machine Learning, Bishop](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)
- [ ] [Applied Predictive Modeling](http://www.springer.com/us/book/9781461468486) ‚Äì M. Kuhn, K. Johnson (2013)
- [ ] [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/181115.pdf) - D.Barber (2015)
- [ ] [Core Concepts in Data Analysis: Summarization, Correlation and Visualization](http://www.springer.com/us/book/9780857292865) - Boris Mirkin
- [ ] [A Course in Machine Learning](http://www.e-booksdirectory.com/details.php?ebook=9395) - Hal Daum√© III ([another link](http://ciml.info))
- [ ] [Data Mining: Concepts and Techniques](http://www.sciencedirect.com/science/book/9780123814791) - Jiawei Han et. al.
- [ ] [Data Mining and Analysis. Fundamental Concepts and Algorithms](http://www.cs.rpi.edu/~zaki/PaperDir/DMABOOK.pdf) - M.J.Zaki, W.Meira Jr (2014)
- [ ] [Data Science For Dummies](https://www.geekbooks.me/book/view/data-science-for-dummies) ‚Äì Lillian Pierson (2015)
- [ ] [Doing Data Science](http://shop.oreilly.com/product/0636920028529.do)
- [ ] [Frequent Pattern Mining](https://mail.google.com/mail/u/1/#inbox/1536859aae027538) - Charu C Aggarwal, Jiawei Han (eds.) 
- [ ] [Gaussian Processes for Machine Learning](http://www.e-booksdirectory.com/details.php?ebook=1774) - Carl E. Rasmussen, Christopher K. I. Williams
- [ ] [Inductive Logic Programming: Techniques and Applications](http://www.e-booksdirectory.com/details.php?ebook=1105) - Nada Lavrac, Saso Dzeroski
- [ ] [Information Theory, Inference and Learning Algorithms](http://www.inference.phy.cam.ac.uk/itila/book.html) ‚Äì David MacKay
- [ ] [Introduction To Machine Learning](http://www.e-booksdirectory.com/details.php?ebook=1117) - Nils J Nilsson (1997)
- [ ] [The LION Way Machine Learning plus Intelligent Optimization](http://1.oito.eu/The-LION-Way-Machine-Learning-plus-Intelligent-Optimization.pdf) (pdf)
- [ ] [Machine Learning](http://personal.disco.unimib.it/Vanneschi/McGrawHill_-_Machine_Learning_-Tom_Mitchell.pdf) - Tom Mitchell
- [ ] [Machine Learning](http://www.mlyearning.org/) ‚Äì Andrew Ng
- [ ] [Machine Learning, Neural and Statistical Classification](http://www.e-booksdirectory.com/details.php?ebook=1118) - D. Michie, D. J. Spiegelhalter
- [ ] [Machine Learning. The Art of Science of Algorithms that Make Sense of Data](http://www.amazon.com/Machine-Learning-Science-Algorithms-Sense/dp/1107422221/) - P. Flach (2012)
- [ ] [Pattern Recognition and Machine Learning](http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/) - C.M.Bishop (2006)
- [ ] [Machine Learning in Action](https://www.manning.com/books/machine-learning-in-action) - Peter Harrington
- [ ] [R in Action](https://www.manning.com/books/r-in-action)
- [ ] [Reinforcement Learning: An Introduction](http://www.e-booksdirectory.com/details.php?ebook=1825) - Richard S. Sutton, Andrew G. Barto
- [ ] [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/%7Eshais/UnderstandingMachineLearning/copy.html)
- [ ] [–ê–Ω–∞–ª–∏–∑ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö](http://dmkpress.com/catalog/computer/data/978-5-97060-190-7/) - –ø–µ—Ä–µ–≤–æ–¥ [Mining Massive Datasets](http://www.mmds.org/) - Jure Leskovec, Anand Rajaraman, Jeff Ullman
- [ ] [–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ](https://www.dropbox.com/s/wkmoxtq0egzcoxc/Flach_P_Machine_Learning_RU.pdf) ‚Äî –ü–µ—Ç–µ—Ä –§–ª–∞—Ö
- [ ] [–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è](https://vk.com/doc190970339_437111950) ‚Äî –õ. –ü. –ö–æ—ç–ª—å–æ, –í. –†–∏—á–∞—Ä—Ç (2016)
- [ ] [–ü–æ–¥–±–æ—Ä–∫–∞ –Ω–∞—É—á–ø–æ–ø-–∫–Ω–∏–≥](https://bookmate.com/bookshelves/Nggk0rBi)

## ‚ñ∂Ô∏è Websites

- [ ] [Talking Machines](https://www.thetalkingmachines.com)

## :octocat: GitHub Repositories

- [ ] [100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
- [ ] [–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/esokolov/ml-course-msu) —Å –∫–æ–Ω—Å–ø–µ–∫—Ç–∞–º–∏, –∫–æ–¥–æ–º –∏ –ø—Ä–æ—á–∏–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∫ —Å–µ–º–∏–Ω–∞—Ä–∞–º –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –í–ú–ö –ú–ì–£
- [ ] [100 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é](http://meta-guide.com/software-meta-guide/100-best-github-machine-learning)
- [ ] [awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning)
- [ ] [Open Source Society University's Data Science](https://github.com/open-source-society/data-science) course ‚Äì this is a solid path for those of you who want to complete a Data Science course on your own time, for free, with courses from the best universities in the World
 - [ ] [–ë–ª–æ–≥–∏ –ø–æ –¥–∞—Ç–∞—Å–∞–µ–Ω—Å-—Ç–µ–º–∞—Ç–∏–∫–µ](https://github.com/rushter/data-science-blogs)
 - [ ] [Dive into Machine Learning](http://hangtwenty.github.io/dive-into-machine-learning/) ([:octocat: repo on github](https://github.com/hangtwenty/dive-into-machine-learning)) with Python Jupyter notebook and scikit-learn
 - [ ] –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π [–∫—É—Ä—Å–∞ ¬´–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∏ Python¬ª](https://github.com/demidovakatya/mashinnoye-obucheniye/tree/master/mathematics-and-python) –∏ [—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏](/spec-recommendations.md)
 - [ ] [–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –®–ê–î](https://gist.github.com/demidovakatya/873e4dd6f1c6652ac842)
 - [ ] [Machine learning cheat sheet](https://github.com/soulmachine/machine-learning-cheat-sheet/raw/master/machine-learning-cheat-sheet.pdf) - soulmachine (2015)
 - [ ] [Probabilistic Programming and Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) (free)
 
## Awesome List 
 
- [ ] [awesome-cs-courses](https://github.com/prakhar1989/awesome-courses#machine-learning)
- [ ] [awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning)
- [ ] [awesome-rnn](https://github.com/kjw0612/awesome-rnn) ‚Äì awesome recurrent neural networks
- [ ] [awesome-python-books](https://github.com/Junnplus/awesome-python-books) - Directory of Python books;
- [ ] [awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets) ‚Äì an awesome list of high-quality open datasets in public domains (on-going)

    
## üìå Other

- [ ] Cheat Sheets:
 - [ ] [Conda Cheat Sheet](https://github.com/ElizaLo/Machine-Learning/blob/master/Other/conda-cheatsheet.pdf)
 - [ ] [NumPy Cheat Sheet](https://github.com/ElizaLo/Machine-Learning/blob/master/Other/Numpy_Python_Cheat_Sheet.pdf)
- [ ] [Tucker Decomposition](https://en.wikipedia.org/wiki/Tucker_decomposition), [Article](https://link.springer.com/article/10.1007/BF02289464)
 - [ ] [Katakoda](https://www.katacoda.com/)
 - [ ] [A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
    - [Code](https://drive.google.com/file/d/16hiZefHVkIb8Cvhf3BbBXsOOV9hob7eo/view)
 - [ ] [–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –≤–≤–æ–¥–Ω–∞—è –ª–µ–∫—Ü–∏—è](http://www.machinelearning.ru/wiki/images/f/fc/Voron-ML-Intro-slides.pdf) ‚Äì –ö. –í. –í–æ—Ä–æ–Ω—Ü–æ–≤
 - [ ] [–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è –ø–æ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç–∞–º (—Ç–µ–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –º–∞—à–∏–Ω)](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf) ‚Äì –ö. –í. –í–æ—Ä–æ–Ω—Ü–æ–≤
 - [ ] –ü–æ—Å—Ç –Ω–∞ reddit: [Machine Learning Books](https://www.reddit.com/r/MachineLearning/comments/1jeawf/machine_learning_books/)
 - [ ] [–î–æ—Å–∫–∞](https://trello.com/b/rbpEfMld/data-science) –ø–æ data science –≤ Trello ‚Äî –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —Ç–µ–º–∞–º (expertise tracks, —è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã)
 - [ ] [People tweeting about ML and AI](http://blog.talla.com/2016/02/people-tweeting-about-machine-learning-and-ai/) ‚Äî –Ω–∞ –∫–æ–≥–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –≤ –¢–≤–∏—Ç—Ç–µ—Ä–µ
 - [ ] [Machine Learning Resource Guide](https://www.dropbox.com/s/z4f9oer4nkyu9tf/MachineLearningResourceGuide.pdf)
 - [ ] [17 —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é](http://tproger.ru/articles/free-programming-books/#machine-learning) –æ—Ç –¢–∏–ø–∏—á–Ω–æ–≥–æ –ü—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–∞
 - [ ] [51 –∏–¥–µ—è](https://www.quora.com/Data-Science/What-are-some-good-toy-problems-in-data-science/answer/Alex-Kamil) –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –∑–∞–¥–∞—á–µ–∫ (*toy data problem*) –≤ Data Science
 - [ ] [Data Science Interview Questions](http://www.itshared.org/2015/10/data-science-interview-questions.html) ‚Äî –æ–≥—Ä–æ–º–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é –Ω–∞ –ø–æ–∑–∏—Ü–∏—é data scientist'–∞
 - [ ] [–ú–Ω–æ–≥–æ –∫–Ω–∏–≥ –ø–æ NLP](https://www.dropbox.com/sh/b1c2ulwua9zy574/AACswS1E0IB9LdPDxQ6fexm4a?dl=0) (Natural Language Processing)
 - [ ] [–°–ø–∏—Å–æ–∫](/datasets.md) –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
 - [ ] –î–ª—è —Ñ–∞–Ω–∞—Ç–æ–≤ [reddit.com](http://www.reddit.com) ‚Äî [–ø–æ–ª–µ–∑–Ω—ã–µ –∏ –≤–µ—Å—ë–ª—ã–µ —Å–∞–±—Ä–µ–¥–¥–∏—Ç—ã](/reddit.md) –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –∏ —Å–º–µ–∂–Ω—ã–º —Ç–µ–º–∞–º
 - [ ] –û—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å [What should I learn in data science in 100 hours?](https://www.quora.com/What-should-I-learn-in-data-science-in-100-hours/answer/Roman-Trusov)

## Neural Networks

- [ ] [–õ–µ–∫—Ü–∏–∏ –ø–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –Ω–µ–π—Ä–æ–Ω–Ω—ã–º —Å–µ—Ç—è–º](http://www.ccas.ru/voron/download/NeuralNets.pdf) ‚Äî –ö. –í. –í–æ—Ä–æ–Ω—Ü–æ–≤
- [ ] [–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –Ω–∞ stepic](https://stepic.org/s/eg4Xe6Ry) ‚Äî —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –æ—Ç –ò–Ω—Å—Ç–∏—Ç—É—Ç–∞ –ë–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏
- [ ] [–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ](https://ulearn.azurewebsites.net/Course/AIML/) ‚Äî –ø—Ä–∏—è—Ç–Ω—ã–µ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ª–µ–∫—Ü–∏–∏ –ø–æ —à–∏—Ä–æ–∫–æ–º—É –Ω–∞–±–æ—Ä—É —Ç–µ–º. –û–¥–∏–Ω –∏–∑ –Ω–µ–º–Ω–æ–≥–∏—Ö –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- [ ] [Neural Networks for Machine Learning](https://www.coursera.org/course/neuralnets). –¶–∏—Ç–∞—Ç–∞: ¬´–Ø —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ñ—Ä–∞–∑—É "–∂–∏–≤–∞—è –ª–µ–≥–µ–Ω–¥–∞" –∏ —Ç–µ–ø–µ—Ä—å –∏—Å–ø—ã—Ç—ã–≤–∞—é —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –∫–∞–∫-—Ç–æ –∏–Ω–∞—á–µ –æ—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å –î–∂–µ—Ñ—Ñ—Ä–∏ –•–∏–Ω—Ç–æ–Ω–∞ (—á–µ–ª–æ–≤–µ–∫–∞, —Å—Ç–æ—è—â–µ–≥–æ —É –∏—Å—Ç–æ–∫–æ–≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π —Å –ø–æ–º–æ—â—å—é –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏) —Å–ª–æ–∂–Ω–æ. –ö—É—Ä—Å —É –Ω–µ–≥–æ –ø–æ–ª—É—á–∏–ª—Å—è –æ—Ç–ª–∏—á–Ω—ã–π¬ª
- [ ] [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html) ‚Äì –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –æ–Ω–ª–∞–π–Ω-–∫–Ω–∏–≥–∞ –ø–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º –∏ –≥–ª—É–±–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é ([:octocat: repo on github](https://github.com/mnielsen/neural-networks-and-deep-learning))
- [ ] [CS231n: Convolutional Neural Networks for Visual Recognition](http://vision.stanford.edu/teaching/cs231n/) ([:octocat: repo on github](https://github.com/cs231n)). During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision
- [ ] [Tensorflow ‚Äî Neural Network Playground](http://playground.tensorflow.org/) ‚Äì –∏–≥—Ä—É—à–µ—á–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ ([:octocat: –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥](https://github.com/tensorflow/playground))
- [ ] [awesome-rnn](https://github.com/kjw0612/awesome-rnn) ‚Äì awesome recurrent neural networks
- [ ] [nmn2](https://github.com/jacobandreas/nmn2) ‚Äì dynamically predicted neural network structures for multi-domain question answering;
- [ ] [Nervana's Deep Learning Course](https://www.nervanasys.com/deep-learning-tutorials/).
    
## Reinforcement Learning 

- [ ] Books:
   - [Reinforcement Learning: An Introduction (2nd Edition)](http://incompleteideas.net/book/RLbook2018.pdf)
- [ ] Classes:
   - [David Silver's Reinforcement Learning Course (UCL, 2015)](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
      - [Introduction to Reinforcement learning with David Silver (DeepMind)](https://www.youtube.com/playlist?list=PLqYmG7hTraZBiG_XpjnPrSNw-1XQaM_gB)
      - [Course website](https://www.davidsilver.uk/teaching/)
      - Introduction to reinforcement learning by one of the leading researchers behind AlphaGo and AlphaZero.
   - [CS294 - Deep Reinforcement Learning (Berkeley, Fall 2015)](http://rail.eecs.berkeley.edu/deeprlcourse/)
   - [CS 8803 - Reinforcement Learning (Georgia Tech)](https://www.udacity.com/course/reinforcement-learning--ud600)
   - [CS885 - Reinforcement Learning (UWaterloo), Spring 2018](https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/)
   - [CS294-112 - Deep Reinforcement Learning (UC Berkeley)](http://rail.eecs.berkeley.edu/deeprlcourse/)
- [ ] Task / Tutorials:
   - [Introduction to Reinforcement Learning (Joelle Pineau @ Deep Learning Summer School 2016)](http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/)
   - [Deep Reinforcement Learning (Pieter Abbeel @ Deep Learning Summer School 2016)](http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/)
   - [Deep Reinforcement Learning ICML 2016 Tutorial (David Silver)](http://techtalks.tv/talks/deep-reinforcement-learning/62360/)
   - [Tutorial: Introduction to Reinforcement Learning with Function Approximation](https://www.youtube.com/watch?v=ggqnxyjaKe4)
   - [John Schulman - Deep Reinforcement Learning (4 Lectures)](https://www.youtube.com/playlist?list=PLjKEIQlKCTZYN3CYBlj8r58SbNorobqcp)
   - [Deep Reinforcement Learning Slides @ NIPS 2016](http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)
   - [OpenAI Spinning Up](https://spinningup.openai.com/en/latest/user/introduction.html)
   - [Advanced Deep Learning & Reinforcement Learning (UCL 2018, DeepMind) -Deep RL Bootcamp](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)
- [ ] GitHub Repositories:
   - [dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning), Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course.
- [ ] [Deep Reinforcment Learning, Decision Making and Control (UC Berkeley CS285)](https://www.youtube.com/playlist?list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A)
- [ ] [New Directions in Reinforcement Learning and Control (Institure for Advanced Study)](https://www.youtube.com/playlist?list=PLdDZb3TwJPZ61sGqd6cbWCmTc275NrKu3)

## Linear Algebra

- [ ] Sheldon Axler "Linear algebra done right"
- [ ] [–ö—É—Ä—Å –ø–æ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä–µ –Ω–∞ stepic](https://stepic.org/course/Linear-Algebra-Problems-and-Methods-79/syllabus)
- [ ] [https://www.coursera.org/course/linalg](https://www.coursera.org/course/linalg)
- [ ] [–ü—Ä–∏–Ω—Å—Ç–æ–Ω](https://www.youtube.com/playlist?list=PLGqzsq0erqU7w7ZrTZ-pWWk4-AOkiGEGp)
- [ ] [http://dshinin.ru/Upload_Books2/Books/2008-07-15/200807152203201.PDF](http://dshinin.ru/Upload_Books2/Books/2008-07-15/200807152203201.PDF)
- [ ] [–ë–æ–π–¥](https://www.youtube.com/playlist?list=PL06960BA52D0DB32B)
- [ ] [https://www.youtube.com/playlist?list=PLbMVogVj5nJQ2vsW_hmyvVfO4GYWaaPp7](https://www.youtube.com/playlist?list=PLbMVogVj5nJQ2vsW_hmyvVfO4GYWaaPp7)
- [ ] [immersive linear algebra](http://immersivemath.com/ila/index.html) ‚Äì online linear algebra book with fully interactive figures
- [ ] [–õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞](https://www.coursera.org/course/linalg) –æ—Ç –í–®–≠. –ö—É—Ä—Å –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä—ã –¥–ª—è –Ω–µ–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–æ–≤, –ø–æ–¥—Ö–æ–¥–∏—Ç ¬´–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞¬ª
- [ ] [MIT 18.06 Linear Algebra](http://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/) ‚Äì by Professor Gilbert Strang


## Theory of Probability and Mathematical Statistics

- [ ] [The Elements of Statistical Learning: Data Mining, Inference, and Prediction](http://www.e-booksdirectory.com/details.php?ebook=3267) - T. Hastie, R. Tibshirani, J. Friedman
- [ ] [Openintro Statistics 3](https://www.openintro.org/stat/textbook.php) (free)
- [ ] [–¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π](http://www.nsu.ru/mmf/tvims/chernova/sibguti/tv-sibguti.pdf) ‚Äì –ß–µ—Ä–Ω–æ–≤–∞ –ù.–ò. (–°–∏–±–ì–£–¢–ò, 2009)
- [ ] [–¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π](http://www.nsu.ru/mmf/tvims/chernova/tv/tv_nsu07.pdf) ‚Äì –ß–µ—Ä–Ω–æ–≤–∞ –ù.–ò. (–ù–ì–£, 2007)
- [ ] [–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](http://www.nsu.ru/mmf/tvims/chernova/ms/ms_nsu14.pdf) ‚Äì –ß–µ—Ä–Ω–æ–≤–∞ –ù.–ò. (–ù–ì–£, 2014)
- [ ] [–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](http://www.nsu.ru/mmf/tvims/chernova/sibguti/ms-sibguti.pdf) ‚Äì –ß–µ—Ä–Ω–æ–≤–∞ –ù.–ò. (–°–∏–±–ì–£–¢–ò, 2009)
- [ ] [–ü—Ä–∏–∫–ª–∞–¥–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](http://www.ozon.ru/context/detail/id/18048756/) ‚Äì –ö–æ–±–∑–∞—Ä—å –ê.
- [ ] [–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞](https://www.coursera.org/learn/modern-combinatorics) –æ—Ç –ú–§–¢–ò, –≤–µ–¥—ë—Ç –†–∞–π–≥–æ—Ä–æ–¥—Å–∫–∏–π –ê.–ú.
- [ ] [–¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö](https://www.coursera.org/learn/probability-theory-basics/home/info) (—Ç–∞–∫–∂–µ [–Ω–∞ OpenEdu](https://openedu.ru/course/mipt/PROBTH/)) ‚Äî –∫—É—Ä—Å –æ—Ç –ú–§–¢–ò, –≤–µ–¥—ë—Ç –†–∞–π–≥–æ—Ä–æ–¥—Å–∫–∏–π –ê.–ú.
- [ ] [Basic Statistics](https://www.coursera.org/learn/basic-statistics) ‚Äì —Ö–æ—Ä–æ—à–∏–µ –ª–µ–∫—Ü–∏–∏ –∏ –∫–≤–∏–∑—ã, –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤. –ú–∏–Ω—É—Å ‚Äî –Ω–µ–¥–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è (_Labs_) –Ω–∞ DataCamp, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–º–æ–≥–∞—é—Ç –∑–∞–∫—Ä–µ–ø–∏—Ç—å –≤—ã—É—á–µ–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª, –∞, —Å–∫–æ—Ä–µ–µ, –æ—Ç–≤–ª–µ–∫–∞—é—Ç –æ—Ç –∏–∑—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- [ ] [Introduction to Probability and Data](https://www.coursera.org/learn/probability-intro/home/welcome) –æ—Ç Duke University
- [ ] [Probability and Statistics](https://www.khanacademy.org/math/probability) –Ω–∞ KhanAcademy
- [ ] [–û—Å–Ω–æ–≤—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏](https://stepic.org/course/76) –Ω–∞ stepic.org ‚Äî –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- [ ] [–û—Å–Ω–æ–≤—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: —á–∞—Å—Ç—å 2](https://stepic.org/course/–û—Å–Ω–æ–≤—ã-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏-–ß–∞—Å—Ç—å-2-524) ‚Äî –∫—É—Ä—Å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –∑–Ω–∞–∫–æ–º–∏—Ç—å —Å–ª—É—à–∞—Ç–µ–ª–µ–π —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø–æ–Ω—è—Ç–∏—è–º–∏ –∏ –º–µ—Ç–æ–¥–∞–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏. –ö—É—Ä—Å –∑–∞—Ç—Ä–æ–Ω–µ—Ç —Ç–∞–∫–∏–µ —Ç–µ–º—ã –∫–∞–∫ –∞–Ω–∞–ª–∏–∑ –Ω–æ–º–∏–Ω–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∏ –º–µ—Ç–æ–¥—ã –ø–æ–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
- [ ] [MITx: 6.041x Introduction to Probability - The Science of Uncertainty](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-1)
- [ ] [Intro to Statistics](https://www.udacity.com/courses/st101) ‚Äî covers visualization, probability, regression and other topics that will help you learn the basic methods of understanding data with statistics
- [ ] [Intro to Descriptive Statistics](https://www.udacity.com/courses/ud827) ‚Äì –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫—É—Ä—Å –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤. This course will teach you the basic terms and concepts in statistics as well as guide you through introductory probability
- [ ] [Intro to Inferential Statistics](https://www.udacity.com/courses/ud201) ‚Äì –∫—É—Ä—Å –∑–Ω–∞–∫–æ–º–∏—Ç —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–æ–Ω—è—Ç–∏—è–º–∏ –∏–Ω–¥—É–∫—Ç–∏–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (t-test, ANOVA, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è, —Ä–µ–≥—Ä–µ—Å—Å–∏—è –∏ –¥—Ä.)
- [ ] [Introduction to Probability](http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science/dp/1466575573/ref=pd_cp_14_1?ie=UTF8&refRID=0CF1J1X0J2JFR5JX7BYP) ‚Äì Joseph K. Blitzstein (2014)
- [ ] [Causal Inference in Statistics: A Primer](http://eu.wiley.com/WileyCDA/WileyTitle/productCd-1119186846,subjectCd-ST2A.html) ‚Äì Pearl J., Glymour M.
- [ ] [An Introduction to Statistical learning](http://www-bcf.usc.edu/~gareth/ISL/) ‚Äì Gareth James, D. Witten et. al
- [ ] [Machine Learning: A Probabilistic Perspective](https://vk.com/doc-44016343_199213512?hash=2ad697dae93b3fea0e&dl=4fa59572a2f58a3219)
- [ ] [Statistics 110: Probability](http://projects.iq.harvard.edu/stat110) ‚Äì –ì–∞—Ä–≤–∞—Ä–¥—Å–∫–∏–π –∫—É—Ä—Å –æ—Ç Joseph K. Blitzstein
- [ ] [Statistics for Hackers](https://speakerdeck.com/jakevdp/statistics-for-hackers) ‚Äî –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –æ —Ç–æ–º, –∫–∞–∫ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å coding skills to "hack statistics"

## Algorithms

- [ ] [Data Structures and Algorithms](https://www.coursera.org/specializations/data-structures-algorithms) ‚Äì —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ Coursera
- [ ] [MIT 6.046J Introduction to Algorithms](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-introduction-to-algorithms-sma-5503-fall-2005/) ‚Äì teaches techniques for the design and analysis of efficient algorithms, emphasizing methods useful in practice
- [ ] [Visualizing Algorithms](https://bost.ocks.org/mike/algorithms/);
- [ ] [–†–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤](https://ru.m.wikibooks.org/wiki/–†–µ–∞–ª–∏–∑–∞—Ü–∏–∏_–∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤)

## Python, IPython, Scikit-learn etc.

- [ ] [Dive into Machine Learning](http://hangtwenty.github.io/dive-into-machine-learning/) ([:octocat: repo on github](https://github.com/hangtwenty/dive-into-machine-learning)) with Python Jupyter notebook and scikit-learn
- [ ] –ó–∞–º–µ—Ç–∫–∞ –ø–æ [IPython Notebook](http://re9ulus.github.io/2016/01/09/ipython-notebook/)
- [ ] [WinPython](https://winpython.github.io) ‚Äì –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤ –ø–∏—Ç–æ–Ω–∞ –∏ –Ω–∞—É—á–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (+Jupyter, +Spyder) –¥–ª—è Windows 7/8/10 ([:octocat: —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ –≥–∏—Ç—Ö–∞–±–µ](https://github.com/winpython/winpython))
- [ ] [awesome-python-books](https://github.com/Junnplus/awesome-python-books) - Directory of Python books
- [ ] –°—Ç–∞—Ç—å—è [Data Munging in Python (using Pandas)](http://www.analyticsvidhya.com/blog/2014/09/data-munging-python-using-pandas-baby-steps-python/) ‚Äî –≤ –ø–æ–º–æ—â—å —Ç–µ–º, –∫—Ç–æ –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —Å Python –∏/–∏–ª–∏ Pandas
- [ ] [Intermediate Python](https://github.com/lancelote/interpy-ru)  ‚Äî (–ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π!) –∫—Ä–∞—Ç–∫–æ–µ –æ–Ω–ª–∞–π–Ω-—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –Ω—é–∞–Ω—Å–∞–º —è–∑—ã–∫–∞, –º–∏–º–æ –∫–æ—Ç–æ—Ä—ã—Ö —á–∞—Å—Ç–æ –ø—Ä–æ—Ö–æ–¥—è—Ç –Ω–æ–≤–∏—á–∫–∏ (–∞–≤—Ç–æ—Ä ‚Äî Yasoob Khalid);
- [ ] [Effective Python](http://www.effectivepython.com/) ‚Äî –∫–Ω–∏–≥–∞ –æ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∏–∑ Google
- [ ] [–í–≤–µ–¥–µ–Ω–∏–µ –≤ Sklearn](https://github.com/Dyakonov/notebooks/blob/master/dj_sklearn_intro.ipynb) ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π IPython-notebook –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- [ ] [–¢—É—Ç–æ—Ä–∏–∞–ª –ø–æ Matplotlib](http://www.labri.fr/perso/nrougier/teaching/matplotlib/matplotlib.html)
- [ ] [–¢–∞–±–ª–∏—Ü–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Ü–≤–µ—Ç–æ–≤ (png)](http://matplotlib.org/1.4.1/mpl_examples/color/named_colors.hires.png) –≤ Python
- [ ] [–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–º–æ—â–∏ Python](http://playittodeath.ru/–∞–Ω–∞–ª–∏–∑-–¥–∞–Ω–Ω—ã—Ö-–ø—Ä–∏-–ø–æ–º–æ—â–∏-python-–≥—Ä–∞—Ñ–∏–∫–∏-–≤-pandas/) ‚Äì –±–æ–ª—å—à–∞—è —Å—Ç–∞—Ç—å—è –ø—Ä–æ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ pandas –∏ matplotlib
- [ ] [Scipy lecture notes](http://www.scipy-lectures.org/index.html) ‚Äî tutorials on the scientific Python ecosystem: a quick introduction to central tools and techniques
- [ ] –û—á–µ–Ω—å [–±–æ–ª—å—à–æ–π —Å–ø–∏—Å–æ–∫](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –ø–∏—Ç–æ–Ω–æ–≤—Å–∫–∏—Ö –Ω–æ—É—Ç–±—É–∫–æ–≤ (–æ—Ç —Ç—É—Ç–æ—Ä–∏–∞–ª–æ–≤ –Ω–∞ —Ç—Ä–∏ –º–∏–Ω—É—Ç—ã, –¥–æ —Ü–µ–ª—ã—Ö –∫–Ω–∏–≥ (!) –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ)
- [ ] [Data Science IPython Notebooks](https://github.com/donnemartin/data-science-ipython-notebooks) on Deep learning (TensorFlow, Theano, Caffe), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.
- [ ] [100 Numpy exercises](http://www.labri.fr/perso/nrougier/teaching/numpy.100/index.html). The goal is both to offer a quick reference for new and old users and to provide also a set of exercices for those who teach
- [ ] [Intro to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science) ‚Äì –æ—Å–Ω–æ–≤—ã Python –∏ –Ω–µ–º–Ω–æ–≥–æ –ø—Ä–æ NumPy
- [ ] [–ö—É—Ä—Å –ø–æ –æ—Å–Ω–æ–≤–∞–º Python, –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º –¥–∞–Ω–Ω—ã—Ö](https://github.com/Yorko/python_intro). –ö—É—Ä—Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Ç–µ—Ç—Ä–∞–¥–æ–∫ IPython
- [ ] [@py_digest](https://telegram.me/py_digest) ‚Äì –∫–∞–Ω–∞–ª –≤ telegram, —É–≤–µ–¥–æ–º–ª—è—é—â–∏–π –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö –∏–∑ –º–∏—Ä–∞ Python
- [ ]  [Python](https://telegram.me/ru_python) ‚Äì –≥—Ä—É–ø–ø–∞ –≤ telegram —Å –æ–±—â–µ–Ω–∏–µ–º –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ–º —è–∑—ã–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è Python
- [ ] [Pythonpedia](https://pythonpedia.com/) ‚Äì —ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –Ω–∞ Python
- [ ] [10 –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö](https://blog.modeanalytics.com/python-data-visualization-libraries/) –Ω–∞ Python
- [ ] [tpot](https://github.com/rhiever/tpot) ‚Äì A Python tool that automatically creates and optimizes machine learning pipelines using genetic programming
- [ ] [Data Analysis Tutorials](https://pythonprogramming.net/data-analysis-tutorials/) ‚Äì Python Programming tutorials from beginner to advanced on a massive variety of topics. All video and text tutorials are free
- [ ] The [python-machine-learning-book](https://github.com/rasbt/python-machine-learning-book) code repository and info resource
- [ ] [introduction to ML with python](https://github.com/amueller/introduction_to_ml_with_python) ‚Äì Notebooks and code for the book "Introduction to Machine Learning with Python"

## Code editors

- [ ]  [PyCharm –æ—Ç JetBrains](http://www.jetbrains.com/pycharm/) - —Å–µ—Ä—å–µ–∑–Ω–∞—è IDE –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
- [ ] [Spyder](https://pythonhosted.org/spyder/) ‚Äì the Scientific PYthon Development EnviRonment. Spyder –≤—Ö–æ–¥–∏—Ç –≤ –ê–Ω–∞–∫–æ–Ω–¥—É (–ø—Ä–æ—Å—Ç–æ –≤–≤–µ–¥–∏—Ç–µ `spyder` –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ)
- [ ] [Canopy](https://store.enthought.com/downloads/#default) ‚Äî scientific and analytic Python deployment with integrated analysis environment (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –≤ –∫—É—Ä—Å–µ MITx)
- [ ] [Rodeo](http://blog.yhat.com/posts/introducing-rodeo.html) ‚Äî a data science IDE for Python
- [ ] [Jupyter](http://jupyter.org) ‚Äì open source, interactive data science and scientific computing across over 40 programming languages. The Jupyter Notebook is a web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text
- [ ] [nbviewer](http://nbviewer.jupyter.org) ‚Äì renders notebooks available on other websites
- [ ] [Sublime Text 3](http://www.sublimetext.com/3) - VIM XXI –≤–µ–∫–∞*;, –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è python, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–º–µ—Å—Ç–µ —Å –ø–ª–∞–≥–∏–Ω–∞–º–∏:
  +  [Package Control](https://packagecontrol.io/) - –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∏ —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏
  +  [Git](https://packagecontrol.io/packages/Git) - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å git
  +  [Jedi](https://packagecontrol.io/packages/Jedi%20-%20Python%20autocompletion) - –¥–µ–ª–∞–µ—Ç –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è Python –±–æ–ª–µ–µ —É–º–Ω—ã–º–∏ –∏ –≥–ª—É–±–æ–∫–∏–º–∏
  +  [SublimeREPL](https://packagecontrol.io/packages/SublimeREPL) - –∑–∞–ø—É—Å–∫–∞–µ—Ç `Read-eval-print loop` –≤ —Å–æ—Å–µ–¥–Ω–µ–π –≤–∫–ª–∞–¥–∫–µ, —É–¥–æ–±–Ω–æ –¥–ª—è –ø–æ—à–∞–≥–æ–≤–æ–π –æ—Ç–ª–∞–¥–∫–∏ –∫–æ–¥–∞
  +  [Auto-PEP8](https://packagecontrol.io/packages/AutoPEP8) - –ø—Ä–∏–≤–æ–¥–∏—Ç –∫–æ–¥ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –∫–∞–Ω–æ–Ω–æ–º —Å—Ç–∏–ª—è *pep8*
  +  [Python Checker](https://packagecontrol.io/packages/Python%20Checker) - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–¥–∞


- [ ]  [PyCharm vs Sublime Text](https://opensourcehacker.com/2015/05/02/pycharm-vs-sublime-text/) ‚Äì a blog post comparing these two popular development tools and text editors. 
- [ ] [PEP 0008](https://www.python.org/dev/peps/pep-0008/) -- Style Guide for Python Code.

## JavaScript-libraries for visualizing

- [ ] [d3.js](https://github.com/d3/d3/wiki/Gallery)
- [ ] [JS Charts](http://www.jscharts.com/) ‚Äì a JavaScript based chart generator that requires little or no coding. With JS Charts drawing charts is a simple and easy task, since you only have to use client-side scripting
- [ ] [LT Diagram Builder](http://www.lutanho.net/)
- [ ] [Flot](http://www.flotcharts.org/) ‚Äì a pure JavaScript plotting library for jQuery, with a focus on simple usage, attractive looks and interactive features
- [ ] Canvas 3D Graph
- [ ] JQuery Visualize Plugin
- [ ] PlotKit
- [ ] http://www.ajaxline.com/10-best-free-javascript-charts-solutions
- [ ] http://webtecker.com/2008/06/12/10-free-chart-scripts/
- [ ] raphaeljs.com
- [ ] www.deensoft.com/lab/protochart/
- [ ] http://teethgrinder.co.uk/open-flash-chart-2

## R

- [ ] [R in Action](https://www.manning.com/books/r-in-action)
- [ ] [Basic Statistics](https://www.coursera.org/learn/basic-statistics) ‚Äì –≤ —ç—Ç–æ–º –∫—É—Ä—Å–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è –Ω–∞ R;
- [ ] [–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ R –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –∏ –∑–∞–¥–∞—á–∞—Ö](http://www.youtube.com/playlist?list=PLlb7e2G7aSpSSa_PlFEwnd6-3gzAa08_m) ‚Äî –≤–∏–¥–µ–æ–ª–µ–∫—Ü–∏–∏ –æ—Ç Computer Science Center;
- [ ] [Advanced R](http://adv-r.had.co.nz) by Hadley Wickham ‚Äì –æ–Ω–ª–∞–π–Ω-–∫–Ω–∏–≥–∞ –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ —Ö–æ—á–µ—Ç –ø–æ–≤—ã—Å–∏—Ç—å —Å–≤–æ–π –Ω–∞–≤—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ R –∏ –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å —ç—Ç–æ—Ç —è–∑—ã–∫ (–≤ —Ç.—á. –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤ –Ω–∞ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö);
- [ ] [A detailed list](http://bafflednerd.com/learn-r-online/) of online courses on R;
- [ ] [Machine Learning in R](http://rpackages.ianhowson.com/cran/mlr/) ([:octocat: github repo](https://github.com/mlr-org/mlr)) ‚Äî Interface to a large number of classification and regression techniques, including machine-readable parameter descriptions;
- [ ] [–õ—É—á—à–∏–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ R](https://habrahabr.ru/company/infopulse/blog/305692/) ‚Äì —Å—Ç–∞—Ç—å—è –Ω–∞ –•–∞–±—Ä–∞—Ö–∞–±—Ä–µ.

## LaTeX

- [ ]  [–ù–µ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ LateX (PDF)](http://zelmanov.ptep-online.com/ctan/lshort_russian.pdf),
- [ ] IDE:
    * [http://www.texstudio.org/](http://www.texstudio.org/), 
    * [https://www.lyx.org/](https://www.lyx.org/),
- [ ] [–ö—É—Ä—Å –ø–æ LateX](https://www.coursera.org/course/latex) –Ω–∞ Coursera –æ—Ç –í—ã—Å—à–µ–π –®–∫–æ–ª—ã –≠–∫–æ–Ω–æ–º–∏–∫–∏*,
- [ ] [https://vk.com/hse.latex](https://vk.com/hse.latex) ‚Äì –≥—Ä—É–ø–ø–∞ –∫—É—Ä—Å–∞ vk  (–º–Ω–æ–≥–æ –ø–æ–ª–µ–∑–Ω–æ–≥–æ –∏ —Ä–∞–∑–Ω–æ–≥–æ).

## üìë Open Datasets list

- [Kaggle](https://www.kaggle.com/datasets)
- [Google‚Äôs Public Data Sets](https://cloud.google.com/bigquery/public-data/)
- [/r/datasets](https://www.reddit.com/r/datasets)
- [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/)
- [awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets) ‚Äì an awesome list of high-quality open datasets in public domains (on-going)

The initial list was provided by Kevyn Collins-Thomson from the University of Michigan School of Information.

- **Long general-purpose list of datasets:** 
    - https://vincentarelbundock.github.io/Rdatasets/datasets.html

- This website has dozens of public datasets - some fun, some a bit, well.. quirky. external link: 
    - https://rs.io/100-interesting-data-sets-for-statistics/

- **The Academic Torrents site** has a growing number of datasets, including a few text collections that might be of interest (Wikipedia, email, twitter, academic, etc.) for current or future projects. 
    - http://academictorrents.com/browse.php?cat=6

- **Google Books n-gram corpus**
    - External link: http://books.google.com/ngrams
    - Dataset: external link: http://aws.amazon.com/datasets/8172056142375670
    
- **Common Crawl:** ‚Ä¢ Currently 6 billion Web documents (81 Tb) ‚Ä¢ Amazon S3 Public Data Set
    - http://aws.amazon.com/datasets/41740
    - https://commoncrawl.atlassian.net/wiki/display/CRWL/About+the+Data+Set
    - Award project using Common Crawl: http://norvigaward.github.io/entries.html
    - Python example: http://www.freelancer.com/projects/Python-Data-Processing/Python-script-for-CommonCrawl.html


- **Business/commercial data Yelp external link:**
    - http://www.yelp.com/developers/documentation/v2/search_api
    - Upcoming Deprecation of Yelp API v2 on June 30, 2018 (Posted by Yelp Jun 28, 2017)
    
- **Internet Archive** (huge, ever-growing archive of the Web going back to 1990s) external link:
    - http://archive.org/help/json.php
    
- **WikiData:**
    - https://www.wikidata.org/wiki/Wikidata:Main_Page

- **World Food Facts**
    - http://world.openfoodfacts.org/data

- **Data USA - a variety of census data**
    - https://datausa.io/
    
- **U.S. Government open data** - datasets from 75 agencies and subagencies
    - https://data.gov/
    
- **NASA data portal** - space and earth science
    - https://data.nasa.gov/ 

## Reddit

- [ ] [/r/datacleaning](https://www.reddit.com/r/datacleaning)
- [ ] [/r/dataisbeautiful](https://www.reddit.com/r/dataisbeautiful)
- [ ] [/r/dataisugly](https://www.reddit.com/r/dataisugly)
- [ ] [/r/datasets](https://www.reddit.com/r/datasets)
- [ ] [/r/MachineLearning](https://www.reddit.com/r/MachineLearning)
- [ ] [/r/probabilitytheory](https://www.reddit.com/r/probabilitytheory)
- [ ] [/r/statistics](https://www.reddit.com/r/statistics)
- [ ] [/r/pystats](https://www.reddit.com/r/pystats)
- [ ] [/r/learnpython](https://www.reddit.com/r/learnpython)

## Social Networks (chanels, chats, groups, etc.)

- [ ] [Deep Learning Russia](https://telegram.me/deeplearning_ru) ‚Äî –ö–∞–Ω–∞–ª —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ vk.com/deeplearning_ru
- [ ] [ModelOverfit](https://telegram.me/modeloverfit) ‚Äî –ö–∞–Ω–∞–ª —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ modeloverfit
- [ ] [Data Science](https://telegram.me/opendatascience) ‚Äî –ü–µ—Ä–≤—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∫–∞–Ω–∞–ª –ø—Ä–æ data science
- [ ] [Big Data & Machine Learning](https://telegram.me/bigdata_ru) ‚Äî –ß–∞—Ç –ø–æ –±–æ–ª—å—à–∏–º –¥–∞–Ω–Ω—ã–º, –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é
- [ ] [Data Science Chat](https://telegram.me/datasciencechat) ‚Äî –ß–∞—Ç –ø–æ —Ç–µ–º–µ Data Science


## What's is the difference between _train, validation and test set_, in neural networks?

**Training Set:** this data set is used to adjust the weights on the neural network.

**Validation Set:** this data set is used to minimize overfitting. You're not adjusting the weights of the network with this data set, you're just verifying that any increase in accuracy over the training data set actually yields an increase in accuracy over a data set that has not been shown to the network before, or at least the network hasn't trained on it (i.e. validation data set). If the accuracy over the training data set increases, but the accuracy over the validation data set stays the same or decreases, then you're overfitting your neural network and you should stop training.

> The **validation data set** is a set of data for the function you want to learn, which you are not directly using to train the network. You are training the network with a set of data which you call the training data set. If you are using gradient based algorithm to train the network then the error surface and the gradient at some point will completely depend on the training data set thus the training data set is being directly used to adjust the weights. To make sure you don't overfit the network you need to input the validation dataset to the network and check if the error is within some range. Because the validation set is not being using directly to adjust the weights of the network, therefore a good error for the validation and also the test set indicates that the network predicts well for the train set examples, also it is expected to perform well when new example are presented to the network which was not used in the training process.

**Testing Set:** this data set is used only for testing the final solution in order to confirm the actual predictive power of the network.

**Also**, in the case you do not have enough data for a validation set, you can use **cross-validation** to tune the parameters as well as estimate the test error.

**Cross-validation set** is used for model selection, for example, select the polynomial model with the least amount of errors for a given parameter set. The test set is then used to report the generalization error on the selected model. 

**[Early stopping](https://en.wikipedia.org/wiki/Early_stopping)** is a way to stop training. There are different variations available, the main outline is, both the train and the validation set errors are monitored, the train error decreases at each iteration ([backpropagation](https://en.wikipedia.org/wiki/Backpropagation) and brothers) and at first the validation error decreases. The training is stopped at the moment the validation error starts to rise. The weight configuration at this point indicates a model, which predicts the training data well, as well as the data which is not seen by the network . But because the validation data actually affects the weight configuration indirectly to select the weight configuration. This is where the Test set comes in. This set of data is never used in the training process. Once a model is selected based on the validation set, the test set data is applied on the network model and the error for this set is found. This error is a representative of the error which we can expect from absolutely new data for the same problem.
 
# ‚öôÔ∏è **Models and Algorithms Implementation:**

 1. ## **k Nearest Neighbor**
    - [Code](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/blob/master/k%20Nearest%20Neighbor/kNN.py)
    - [Subset of MNIST](https://pjreddie.com/projects/mnist-in-csv/)

 2. ## **Linear Regression**
    - üìò [Math](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#linear-regression)
      - ["Batch" Gradient Descent](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#batch-gradient-descent)
      - [Gradient Descent For Linear Regression](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#gradient-descent-for-linear-regression)
      - [Gradient Descent For Multiple Variables](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#gradient-descent-for-multiple-variables)
    - üìò [Polynomial Regression](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/tree/master/P2#polynomial-regression)
    - üíª [Code](https://github.com/ElizaLo/ML-with-Jupiter/tree/master/P2)
    
 3. ## **Logistic Regression**
    - [Code](https://github.com/ElizaLo/ML-with-Jupiter/tree/master/P3)
 
 4. ## **Fully Connected Neural Networks**
    - Fully connected neural network that recognizes handwriting numbers from  MNIST database (Modified National Institute of     Standards and Technology database)
    - [MNIST Database](https://pjreddie.com/projects/mnist-in-csv/)
    - [Code](https://github.com/ElizaLo/ML-with-Jupiter/tree/master/P4)   
    
5. ## **Convolutional Neural Network (CNN)**
    - [Code](https://github.com/ElizaLo/ML-with-Jupiter/tree/master/P7)
    
6. ## **Gated Recurrent Units (GRU)**
    - [Understanding GRU Networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be), Towards Data Science
 
 
# üë©‚Äçüíª Projects: 

 - # **Spam Detection**
 
   ‚öôÔ∏è Methods:
    - **_Naive Bayes spam filtering_**
    - **_K-Nearest Neighbors algorithm_**
    - **_Decision Tree learning_**
    - **_Support Vector Machine (SVM)_**
    - **_Random Forest_**
    
 - üíª [Code](https://github.com/ElizaLo/ML-with-Jupiter/blob/master/Spam%20Detection/Spam_Detection.ipynb)
 - [SMS Spam Collection Dataset](https://github.com/ElizaLo/ML-with-Jupiter/blob/master/Spam%20Detection/spam.csv)
  
 - # **Text Generator**
   
   Neural Network for generating text based on training txt file using **_Google Colab_**. 
   As a base text were used **_Alice in Wonderland_** by Lewis Carroll.
   
    - üíª [Code](https://github.com/ElizaLo/ML-using-Jupiter-Notebook-and-Google-Colab/blob/master/Text%20Generator/Text_Generator.ipynb)
    - [Base text - **Alice in Wonderland**](https://github.com/ElizaLo/ML-with-Jupiter/blob/master/Text%20Generator/alice_in_wonderland.txt)
    - [Formatted text of **Alice in Wonderland**](https://github.com/ElizaLo/ML-with-Jupiter/blob/master/Text%20Generator/alice_formatted.txt)
    
 - # Question Answering System using BiDAF Model on SQuAD
   
   Implemented a Bidirectional Attention Flow neural network as a baseline on SQuAD, improving Chris Chute's model [implementation](https://github.com/chrischute/squad/blob/master/layers.py), adding word-character inputs as described in the original paper and improving [GauthierDmns' code](https://github.com/GauthierDmn/question_answering).
   
    - [Project Repository](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD)
    - [Paper](https://github.com/ElizaLo/NLP/blob/master/Question%20Answering%20System/Question%20Answering%20System%20based%20on%20SQuAD.pdf)
    - [Used Articles](https://github.com/ElizaLo/NLP/tree/master/Question%20Answering%20System/Articles)
    - [Useful Articles](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD#useful-articles)
    - [Useful Links](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD#useful-links)
  
